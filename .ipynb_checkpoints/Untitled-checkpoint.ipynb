{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced9b1a4-d572-4e93-8592-538d0ce5b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Image Tagger with Color Detection\n",
      "==================================================\n",
      "Analyzing full body image: images/person2.jpg\n",
      "============================================================\n",
      "👕 TOPWEAR:\n",
      "   t-shirt: 0.061 (6.1%)\n",
      "   shirt: 0.060 (6.0%)\n",
      "   polo shirt: 0.060 (6.0%)\n",
      "\n",
      "👖 BOTTOMWEAR:\n",
      "   jeans: 0.069 (6.9%)\n",
      "   joggers: 0.068 (6.8%)\n",
      "   capris: 0.068 (6.8%)\n",
      "\n",
      "👗 FULL OUTFIT CHECK:\n",
      "   overall: 0.105 (10.5%)\n",
      "\n",
      "🎨 COLORS:\n",
      "   Topwear: denim blue (1.7%)\n",
      "   Bottomwear: denim blue (1.7%)\n",
      "\n",
      "📝 OUTFIT DESCRIPTION:\n",
      "   denim blue t-shirt and denim blue jeans\n",
      "\n",
      "✨ Final Result: denim blue t-shirt and denim blue jeans\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def tag_image(image_path):\n",
    "    \"\"\"\n",
    "    Analyze full body images to detect topwear, bottomwear, and their colors\n",
    "    Just provide the path to your image!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Topwear categories\n",
    "    topwear = [\n",
    "        \"t-shirt\", \"shirt\", \"blouse\", \"tank top\", \"polo shirt\", \"dress shirt\",\n",
    "        \"sweater\", \"hoodie\", \"jacket\", \"blazer\", \"coat\", \"cardigan\", \n",
    "        \"vest\", \"crop top\", \"tube top\", \"halter top\", \"camisole\"\n",
    "    ]\n",
    "    \n",
    "    # Bottomwear categories  \n",
    "    bottomwear = [\n",
    "        \"jeans\", \"pants\", \"trousers\", \"shorts\", \"skirt\", \"leggings\",\n",
    "        \"sweatpants\", \"chinos\", \"cargo pants\", \"dress pants\", \"joggers\",\n",
    "        \"capris\", \"culottes\", \"palazzo pants\", \"wide leg pants\"\n",
    "    ]\n",
    "    \n",
    "    # Dresses and full outfits\n",
    "    full_outfits = [\n",
    "        \"dress\", \"gown\", \"sundress\", \"maxi dress\", \"mini dress\", \n",
    "        \"cocktail dress\", \"evening dress\", \"jumpsuit\", \"romper\", \"overall\"\n",
    "    ]\n",
    "    \n",
    "    # Colors to test against\n",
    "    colors = [\n",
    "        \"red\", \"crimson\", \"scarlet\", \"burgundy\", \"maroon\",\n",
    "        \"blue\", \"navy\", \"sky blue\", \"denim blue\", \"royal blue\", \"baby blue\",\n",
    "        \"green\", \"olive\", \"mint\", \"lime\", \"forest green\", \"teal\",\n",
    "        \"yellow\", \"mustard\", \"gold\", \"lemon\", \"cream\",\n",
    "        \"orange\", \"coral\", \"peach\", \"burnt orange\", \"amber\",\n",
    "        \"purple\", \"lavender\", \"violet\", \"plum\", \"mauve\",\n",
    "        \"pink\", \"hot pink\", \"rose\", \"blush\", \"fuchsia\",\n",
    "        \"black\", \"charcoal\", \"jet black\",\n",
    "        \"white\", \"ivory\", \"off-white\", \"cream\",\n",
    "        \"gray\", \"silver\", \"slate\", \"ash gray\",\n",
    "        \"brown\", \"tan\", \"beige\", \"khaki\", \"chocolate\",\n",
    "        \"cyan\", \"turquoise\", \"aqua\", \"sea green\",\n",
    "        \"gold\", \"silver\", \"bronze\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        print(f\"Analyzing full body image: {image_path}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # ===== TOPWEAR DETECTION =====\n",
    "        top_prompts = [f\"person wearing {item}\" for item in topwear]\n",
    "        top_inputs = clip.tokenize(top_prompts).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_input)\n",
    "            top_features = model.encode_text(top_inputs)\n",
    "            \n",
    "            # Normalize features\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            top_features = top_features / top_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Calculate similarities\n",
    "            top_similarities = (image_features @ top_features.T).softmax(dim=-1)\n",
    "            \n",
    "            # Get top 3 topwear predictions\n",
    "            top_probs, top_indices = top_similarities[0].topk(3)\n",
    "            \n",
    "            print(\"👕 TOPWEAR:\")\n",
    "            topwear_results = []\n",
    "            for i in range(3):\n",
    "                item = topwear[top_indices[i]]\n",
    "                confidence = top_probs[i].item()\n",
    "                print(f\"   {item}: {confidence:.3f} ({confidence*100:.1f}%)\")\n",
    "                topwear_results.append((item, confidence))\n",
    "        \n",
    "        # ===== BOTTOMWEAR DETECTION =====\n",
    "        bottom_prompts = [f\"person wearing {item}\" for item in bottomwear]\n",
    "        bottom_inputs = clip.tokenize(bottom_prompts).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            bottom_features = model.encode_text(bottom_inputs)\n",
    "            bottom_features = bottom_features / bottom_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Calculate similarities\n",
    "            bottom_similarities = (image_features @ bottom_features.T).softmax(dim=-1)\n",
    "            \n",
    "            # Get top 3 bottomwear predictions\n",
    "            bottom_probs, bottom_indices = bottom_similarities[0].topk(3)\n",
    "            \n",
    "            print(\"\\n👖 BOTTOMWEAR:\")\n",
    "            bottomwear_results = []\n",
    "            for i in range(3):\n",
    "                item = bottomwear[bottom_indices[i]]\n",
    "                confidence = bottom_probs[i].item()\n",
    "                print(f\"   {item}: {confidence:.3f} ({confidence*100:.1f}%)\")\n",
    "                bottomwear_results.append((item, confidence))\n",
    "        \n",
    "        # ===== FULL OUTFIT CHECK =====\n",
    "        outfit_prompts = [f\"person wearing {item}\" for item in full_outfits]\n",
    "        outfit_inputs = clip.tokenize(outfit_prompts).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outfit_features = model.encode_text(outfit_inputs)\n",
    "            outfit_features = outfit_features / outfit_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Calculate similarities\n",
    "            outfit_similarities = (image_features @ outfit_features.T).softmax(dim=-1)\n",
    "            \n",
    "            # Get top outfit prediction\n",
    "            outfit_prob, outfit_index = outfit_similarities[0].topk(1)\n",
    "            \n",
    "            best_outfit = full_outfits[outfit_index[0]]\n",
    "            outfit_confidence = outfit_prob[0].item()\n",
    "            \n",
    "            print(f\"\\n👗 FULL OUTFIT CHECK:\")\n",
    "            print(f\"   {best_outfit}: {outfit_confidence:.3f} ({outfit_confidence*100:.1f}%)\")\n",
    "        \n",
    "        # ===== COLOR DETECTION =====\n",
    "        # Check colors for topwear\n",
    "        top_color_prompts = [f\"person wearing {color} top\" for color in colors]\n",
    "        top_color_inputs = clip.tokenize(top_color_prompts).to(device)\n",
    "        \n",
    "        # Check colors for bottomwear  \n",
    "        bottom_color_prompts = [f\"person wearing {color} bottom\" for color in colors]\n",
    "        bottom_color_inputs = clip.tokenize(bottom_color_prompts).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            top_color_features = model.encode_text(top_color_inputs)\n",
    "            bottom_color_features = model.encode_text(bottom_color_inputs)\n",
    "            \n",
    "            top_color_features = top_color_features / top_color_features.norm(dim=-1, keepdim=True)\n",
    "            bottom_color_features = bottom_color_features / bottom_color_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Calculate color similarities\n",
    "            top_color_sims = (image_features @ top_color_features.T).softmax(dim=-1)\n",
    "            bottom_color_sims = (image_features @ bottom_color_features.T).softmax(dim=-1)\n",
    "            \n",
    "            # Get top colors\n",
    "            top_color_prob, top_color_idx = top_color_sims[0].topk(1)\n",
    "            bottom_color_prob, bottom_color_idx = bottom_color_sims[0].topk(1)\n",
    "            \n",
    "            top_color = colors[top_color_idx[0]]\n",
    "            bottom_color = colors[bottom_color_idx[0]]\n",
    "            \n",
    "            print(f\"\\n🎨 COLORS:\")\n",
    "            print(f\"   Topwear: {top_color} ({top_color_prob[0].item()*100:.1f}%)\")\n",
    "            print(f\"   Bottomwear: {bottom_color} ({bottom_color_prob[0].item()*100:.1f}%)\")\n",
    "        \n",
    "        # ===== FINAL DESCRIPTION =====\n",
    "        best_top = topwear_results[0][0]\n",
    "        best_bottom = bottomwear_results[0][0]\n",
    "        \n",
    "        # Check if it's more likely a dress/full outfit\n",
    "        if outfit_confidence > 0.3:  # If dress/outfit confidence is high\n",
    "            description = f\"{colors[top_color_idx[0]]} {best_outfit}\"\n",
    "            outfit_type = \"full_outfit\"\n",
    "        else:\n",
    "            description = f\"{top_color} {best_top} and {bottom_color} {best_bottom}\"\n",
    "            outfit_type = \"separates\"\n",
    "        \n",
    "        print(f\"\\n📝 OUTFIT DESCRIPTION:\")\n",
    "        print(f\"   {description}\")\n",
    "        \n",
    "        return {\n",
    "            'topwear': topwear_results,\n",
    "            'bottomwear': bottomwear_results,\n",
    "            'full_outfit': (best_outfit, outfit_confidence),\n",
    "            'top_color': top_color,\n",
    "            'bottom_color': bottom_color,\n",
    "            'description': description,\n",
    "            'type': outfit_type\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your image path\n",
    "    image_path = \"images/person3.webp\"  # Change this to your actual image path\n",
    "    \n",
    "    print(\"CLIP Image Tagger with Color Detection\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Tag the image\n",
    "    results = tag_image(image_path)\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n✨ Final Result: {results['description']}\")\n",
    "\n",
    "# To use this code:\n",
    "# 1. Save a full body image in the same folder as this notebook\n",
    "# 2. Change the image_path variable to your image filename\n",
    "# 3. Run the code!\n",
    "\n",
    "# Example:\n",
    "# tag_image(\"person_outfit.jpg\")\n",
    "# tag_image(\"full_body_photo.png\") \n",
    "\n",
    "# You can also create quick functions:\n",
    "def quick_outfit_description(image_path):\n",
    "    \"\"\"One-liner to get full outfit description\"\"\"\n",
    "    result = tag_image(image_path)\n",
    "    return result['description'] if result else \"Could not analyze image\"\n",
    "\n",
    "def get_outfit_breakdown(image_path):\n",
    "    \"\"\"Get detailed breakdown of the outfit\"\"\"\n",
    "    result = tag_image(image_path)\n",
    "    if result:\n",
    "        if result['type'] == 'full_outfit':\n",
    "            return f\"Wearing a {result['description']}\"\n",
    "        else:\n",
    "            return f\"Top: {result['top_color']} {result['topwear'][0][0]}, Bottom: {result['bottom_color']} {result['bottomwear'][0][0]}\"\n",
    "    return \"Could not analyze image\"\n",
    "\n",
    "# Usage examples:\n",
    "# quick_outfit_description(\"my_outfit.jpg\") \n",
    "# # Returns: \"black t-shirt and blue jeans\" or \"red dress\"\n",
    "\n",
    "# get_outfit_breakdown(\"my_outfit.jpg\")\n",
    "# # Returns: \"Top: black t-shirt, Bottom: blue jeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df817e-e93d-437d-83e4-50cd7e1f67a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
